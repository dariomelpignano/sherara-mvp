ARTIFICIAL INTELLIGENCE ACT - PROPOSAL FOR A REGULATION
[LAST UPDATED: 2025-07-06]
[VERSION: 2021/0106(COD)]
[STATUS: proposal - adopted by European Parliament]
[OFFICIAL SOURCE: https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206]

TITLE I - GENERAL PROVISIONS

Article 1 - Subject matter
This Regulation lays down:
(a) harmonised rules for placing on the market and putting into service AI systems;
(b) prohibitions of certain AI practices;
(c) specific requirements for high-risk AI systems;
(d) harmonised transparency rules;
(e) rules on market monitoring and surveillance.

Article 2 - Scope
This Regulation applies to:
(a) providers placing on the market or putting into service AI systems in the Union;
(b) users of AI systems located within the Union;
(c) providers and users of AI systems located in third countries where output is used in the Union.

TITLE II - PROHIBITED ARTIFICIAL INTELLIGENCE PRACTICES

Article 5 - Prohibited AI practices
The following AI practices shall be prohibited:
(a) AI systems using subliminal techniques beyond consciousness to materially distort behavior;
(b) AI systems exploiting vulnerabilities of specific groups due to age, disability causing harm;
(c) AI systems for social scoring by public authorities;
(d) Real-time remote biometric identification in publicly accessible spaces for law enforcement (with exceptions).

TITLE III - HIGH-RISK AI SYSTEMS

Chapter 1 - Classification of AI systems as high-risk

Article 6 - Classification rules for high-risk AI systems
AI systems shall be considered high-risk when:
1. Intended as safety component or is itself a product covered by Union harmonisation legislation;
2. Required to undergo third-party conformity assessment;
3. Listed in Annex III areas including:
   - Biometric identification
   - Critical infrastructure
   - Education and vocational training
   - Employment and workers management
   - Essential services and benefits
   - Law enforcement
   - Migration and border control
   - Justice and democratic processes

Chapter 2 - Requirements for high-risk AI systems

Article 8 - Compliance with requirements
High-risk AI systems shall comply with requirements concerning:
- Risk management system
- Data and data governance
- Technical documentation
- Record-keeping
- Transparency and information to users
- Human oversight
- Accuracy, robustness and cybersecurity

Article 9 - Risk management system
A risk management system shall be established consisting of:
(a) identification and analysis of known and foreseeable risks;
(b) estimation and evaluation of risks;
(c) evaluation of other risks based on data analysis;
(d) adoption of risk management measures.

Article 10 - Data and data governance
Training, validation and testing data sets shall be:
- Relevant, representative, free of errors and complete;
- Subject to appropriate data governance practices;
- Taking into account the specific geographical, behavioral or functional setting.

Article 11 - Technical documentation
Technical documentation shall be drawn up before placing on market and include:
- General description of the AI system;
- Detailed description of system elements and development process;
- Information on monitoring, functioning and control;
- Description of risk management measures;
- Description of changes made throughout lifecycle.

Article 12 - Record-keeping
High-risk AI systems shall be designed with capabilities enabling automatic recording of events ('logs').

Article 13 - Transparency and provision of information
High-risk AI systems shall be designed to ensure operation is sufficiently transparent to enable users to interpret output and use it appropriately.

Article 14 - Human oversight
High-risk AI systems shall be designed to enable effective oversight by natural persons including:
- Understanding capabilities and limitations;
- Monitoring operation for anomalies;
- Ability to intervene or interrupt;
- Ability to refuse, override or reverse output.

Article 15 - Accuracy, robustness and cybersecurity
High-risk AI systems shall be designed to achieve appropriate levels of accuracy, robustness and cybersecurity, and perform consistently throughout lifecycle.

Chapter 3 - Obligations of providers and users

Article 16 - Obligations of providers
Providers of high-risk AI systems shall:
- Ensure compliance with requirements;
- Have quality management system in place;
- Draw up technical documentation;
- Keep logs automatically generated;
- Ensure conformity assessment;
- Register system in EU database;
- Take corrective actions;
- Inform authorities of risks.

Article 28 - Obligations of users
Users of high-risk AI systems shall:
- Use systems in accordance with instructions;
- Ensure input data is relevant;
- Monitor operation;
- Keep logs;
- Inform provider of risks or incidents.

TITLE IV - TRANSPARENCY OBLIGATIONS

Article 52 - Transparency obligations for certain AI systems
1. AI systems intended to interact with natural persons shall inform of AI interaction;
2. Emotion recognition or biometric categorization shall inform of operation;
3. Deep fake systems shall disclose content is artificially generated.

TITLE V - MEASURES IN SUPPORT OF INNOVATION

Article 53 - AI regulatory sandboxes
AI regulatory sandboxes shall provide controlled environment to develop, test and validate innovative AI systems.

Article 54 - Further processing of data for AI development
Personal data may be processed for AI development in regulatory sandbox under specific conditions.

TITLE VI - GOVERNANCE

Article 56 - European Artificial Intelligence Board
A European Artificial Intelligence Board shall be established to:
- Facilitate cooperation between national authorities;
- Coordinate and contribute to guidance;
- Assist Commission;
- Collect and share expertise.

Article 59 - National competent authorities
Member States shall designate national competent authorities for supervising application and implementation.

TITLE VIII - POST-MARKET MONITORING

Article 61 - Post-market monitoring by providers
Providers shall establish post-market monitoring system proportionate to nature of AI technologies.

Article 62 - Reporting of serious incidents
Providers shall report serious incidents or malfunctioning to relevant authorities.

TITLE X - PENALTIES

Article 71 - Administrative fines
Non-compliance shall be subject to administrative fines up to:
- 30,000,000 EUR or 6% of worldwide annual turnover for prohibited practices;
- 20,000,000 EUR or 4% for non-compliance with requirements;
- 10,000,000 EUR or 2% for incorrect information.